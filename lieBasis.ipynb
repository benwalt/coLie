{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "-----------------\n",
    "-----------------\n",
    "###  Making Bases!\n",
    "\n",
    "Below, I'll convert my old pairing.html javascript code from the\n",
    "[Lie Algebra / coalgebra pairing calculator](https://drive.google.com/file/d/1j3pHzz9CqklB8YfgB96CbUD1RmiZlN_f/view)\n",
    "to python. I'll also write a new algorithm to generate the star basis for symbols.\n",
    "\n",
    "This section will mostly target Lie algebra - coalgebra pairings.  The next section will look at finitely presented groups and bases for configuration braiding invariants.\n",
    "\n",
    "Note: this code requires the [coLie.py](https://cocalc.com/share/public_paths/4a54e77fae1a6040ef22aefcab5b0ca127a38420) library of coLie objects.\n",
    "\n",
    "----------------------\n",
    "### Lyndon-Shirshov words\n",
    "\n",
    "The Lyndon words (or **Lyndon-Shirshov** acknowledging Anatoly Shirshov using them in 1953 vs Roger Lyndon's use in 1954) appear in algebra, combinatorics, and computer science.  They can be used for data compression, are a basis for the shuffle algebra, index irreducible monic polynomials, and give rise to a Hall basis for Lie algebras.\n",
    "\n",
    "* Given an ordered alphabet, we consider **necklaces** -- words modulo cyclic permutation.  We identify necklaces by writing a representative (modulo cyclic permutation) which is *minimal in lexicographic ordering*.  \n",
    "* A necklace $a_1a_2\\cdots a_N$ is **periodic** if there is $n<N$ so that $a_i = a_{n+i}$ for all $i$ (where this makes sense).  This implies that the necklace is a repetition of multiple copies of some (letter or) subword $\\omega = \\alpha \\alpha \\cdots \\alpha$.\n",
    "* An **LS-word** is a representative of an *aperiodic necklace*.  Note that in this case, the representative choice is unique!\n",
    "\n",
    "Two other characterizations of Lyndon words are helpful when making proofs:\n",
    "* $w$ is LS iff for any (nontrivial) factorization $w=ab$ we have $a < b$ lexicographically\n",
    "* $w$ is LS iff for any (nontrivial) factorization $w=ab$ we have $w < b$ lexicographically (\"$w$ less than its suffixes\")\n",
    "\n",
    "Using the characterizations above we define the \"standard factorization\" of an LS word to be $w=ab$ where $a$ and $b$ are LS and $b$ is as large as possible.  This is used to make the standard bracketing... though there are other good factorizations which lead to interesting bracketings as well.\n",
    "\n",
    "There are a couple of different ways to generate LS words. \n",
    "* In 1988 Duval proposed an algorithm which generates all words of length $n$ by repeating a prefix string and then incrementing the final letter.  This will generate all LS words *in increasing order*.  This algorithm frequently generates words which are too small during its search, but the [average cost of generating the next letter is linear](https://site.ada.edu.az/~medv/acm/Articles/string/lindon/1994AverageCostDuval.pdf).\n",
    "* In 2000 [Cattal et al](https://www.cis.uoguelph.ca/~sawada/papers/un.pdf) propose an alternate algorithm which generates all LS words up to a given length *in reverse order*, modifying one letter at a time.  This algorithm uses the factorization characterization of LS words to iteratively build words which could be prefixes of an LS word.\n",
    "* Afterwards the coauthor J.Sawada modified the algorithm to efficiently target only LS words which contain specified multiplicities of letters.  This is best for our purposes, and is considerably faster than generating all LS words and then tossing out the ones with the wrong multiplicities.\n",
    "* There are other algorithms as well - see [Kopparty et al](https://theoryofcomputing.org/articles/v012a007/v012a007.pdf)\n",
    "\n",
    "Lyndon words are pretty nice and extensively studied and used, but there are also other ways to choose representatives of words modulo shuffles... which can lead to useful and interesting constructions.  The \"deg-lex minimal\" (DL) words is one other choice (natural from the viewpoint of left-greedy brackets and star symbols). \n",
    "\n",
    "Probably any basis of coLie (Eil) words must give a complete set of representatives.  So hunting for bases could be a fruitful way to look for / prove that you've found other rules for making representatives."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "import math   # Duval's algorithm genLS_old() uses math.ceil()\n",
    "\n",
    "#######################################################################\n",
    "def genLS_old(word):\n",
    "    \"\"\"Use Duval's algorithm (1988) to generate all Lyndon(-Shirshov) words using given alphabet and multiplicities\n",
    "       Duval's algorithm generates all words of a given length.  We ignore words with incorrect multiplicities.\n",
    "    \"\"\"\n",
    "    \n",
    "    # create alphabet = list of (letter,count) pairs\n",
    "    alphabet = sorted(list(set(word)))\n",
    "    count    = [word.count(letter) for letter in alphabet]\n",
    "\n",
    "    \n",
    "    if alphabet == []:\n",
    "        return\n",
    "    \n",
    "    N = len(word)\n",
    "   \n",
    "    LSWord = [alphabet[0]]\n",
    "    \n",
    "    # apply algorithm from Duval (1988)\n",
    "    \n",
    "    while LSWord != []:\n",
    "        if len(LSWord) == len(word) and all([LSWord.count(l)==n for l,n in zip(alphabet,count)]):\n",
    "            yield(''.join(LSWord))\n",
    "            \n",
    "        LSWord = LSWord * math.ceil(N/len(LSWord))\n",
    "                \n",
    "        n = N-1\n",
    "        \n",
    "        while n >= 0 and LSWord[n] == alphabet[-1]:\n",
    "            n -= 1\n",
    "            \n",
    "        LSWord = LSWord[:n+1]\n",
    "        \n",
    "        if n >= 0:\n",
    "            LSWord[n] = alphabet[alphabet.index(LSWord[n])+1]\n",
    "            \n",
    "    return\n",
    "\n",
    "\n",
    "#######################################################################\n",
    "# An alternate algorithm is given by Cattell et al (2000) \n",
    "#   https://www.cis.uoguelph.ca/~sawada/papers/un.pdf\n",
    "#\n",
    "# This seems to be about the same speed as Duval's algorithm\n",
    "#\n",
    "def genLS_all(word, t=1, p=1, N=None, K=None, root=True, LSWord=None):\n",
    "    \"\"\"Cattell et al (2000) algorithm generating all LS words of a given length\n",
    "       Running time is similar to Duval (1998)\n",
    "    \"\"\"\n",
    "    if root:\n",
    "        N = len(word)\n",
    "        if N < 2:\n",
    "            yield word\n",
    "        \n",
    "        LSWord = [0] * (N + 1)    # Cattell's algorithm uses 1-indexing... ugh\n",
    "        word   = sorted(list(set(word)))  # later iterations need alphabet\n",
    "        K      = len(word)\n",
    "        \n",
    "        \n",
    "    if t > N:\n",
    "        if p == N:\n",
    "            yield(''.join(word[num] for num in LSWord[1:]))\n",
    "    else:\n",
    "        LSWord[t] = LSWord[t-p]\n",
    "        yield from genLS_all(word, t+1, p, N, K, False, LSWord)\n",
    "        \n",
    "        for j in range(LSWord[t-p]+1, K):\n",
    "            LSWord[t] = j\n",
    "            yield from genLS_all(word, t+1, t, N, K, False, LSWord)\n",
    "\n",
    "\n",
    "#######################################################################\n",
    "#######################################################################            \n",
    "# It is possible to modify Cattell's algorithm to generate only words with specific multiplicies of letters\n",
    "#  below is modification of Joe Sawada's C code (2019) available at http://combos.org/necklace\n",
    "#\n",
    "# This is considerably faster than generating everything and throwing out ones with wrong multiplicity\n",
    "#\n",
    "# We use a linked list to track multiplicity and availability of letters in the alphabet\n",
    "#  Once all of a letter's multiplicity is used up, we modify the linked list to skip it\n",
    "# As we build a LS word, the alphabet linked list will be continually updated adding and removing letters\n",
    "#\n",
    "######################################################\n",
    "# The LListElement class has attributes\n",
    "#   value = multiplicity of an letter\n",
    "#   index = index of the letter\n",
    "#   prev  = previous element in alphabet\n",
    "#   next  = next element in alphabet\n",
    "###########################################################\n",
    "class LListElement:\n",
    "    def __init__(self,value=0,index=0,n=None,p=None):\n",
    "        self.value , self.index = value , index\n",
    "        self._prev , self._next = p , n\n",
    "        \n",
    "    def __bool__(self):\n",
    "        return self.value != 0\n",
    "\n",
    "#######################################################\n",
    "# The ValuedList class will be used to store the alphabet\n",
    "# Attributes:\n",
    "#   _nodes = array containing all linked list elements \n",
    "#   head   = first available element in alphabet \n",
    "#\n",
    "# Methods:\n",
    "#   mult(n)      = remaining multiplicity of letter n\n",
    "#   decrement(n) = lowers available multiplicity of n (and maybe removes from alphabet)\n",
    "#   increment(n) = raises available multiplicity of n (and maybe reinserts in alphabet)\n",
    "#   nextval(n)   = get next available letter (after n)\n",
    "###########################################################\n",
    "class ValuedLList:\n",
    "    def __init__(self,count):\n",
    "        if len(count) < 1:\n",
    "            return\n",
    "         \n",
    "        self._nodes  = [LListElement(count[0])]\n",
    "        for n in range(1,len(count)):\n",
    "            self._nodes.append(LListElement(count[n],n,self._nodes[n-1]))\n",
    "            self._nodes[n-1]._prev = self._nodes[n]\n",
    "            \n",
    "        self.head = self._nodes[-1]\n",
    "    \n",
    "    def mult(self,n):\n",
    "        return self._nodes[n].value\n",
    "    \n",
    "    def decrement(self,n):\n",
    "        self._nodes[n].value -= 1\n",
    "        \n",
    "        if not self._nodes[n]:\n",
    "            if self.head == self._nodes[n]:\n",
    "                self.head = self._nodes[n]._next\n",
    "                \n",
    "            if self._nodes[n]._next:\n",
    "                self._nodes[n]._next._prev = self._nodes[n]._prev\n",
    "            if self._nodes[n]._prev:\n",
    "                self._nodes[n]._prev._next = self._nodes[n]._next\n",
    "\n",
    "    def increment(self,n):\n",
    "        if not self._nodes[n]:\n",
    "            if self._nodes[n]._next:\n",
    "                self._nodes[n]._next._prev = self._nodes[n]\n",
    "            if self._nodes[n]._prev:\n",
    "                self._nodes[n]._prev._next = self._nodes[n]\n",
    "            else:\n",
    "                self.head = self._nodes[n]\n",
    "                \n",
    "        self._nodes[n].value += 1\n",
    "\n",
    "    def nextval(self,n):\n",
    "        if self._nodes[n]._next:\n",
    "            return self._nodes[n]._next.index\n",
    "        return -1\n",
    "    \n",
    "###########################################################\n",
    "# TODO:  allow alphabet with multiplicity to be specified in other ways\n",
    "#\n",
    "#  currently:   \"aaabbbcc\"\n",
    "#  also allow:  [ (\"a\",3) , (\"b\",3) , (\"c\",2) ]  \n",
    "#      (dictionary, list of tuples, list of lists)\n",
    "###########################################################\n",
    "def genLS(word, t=2, p=1, s=2, N=None, K=None, root=True, LSWord=None, count=None, tmp=None):\n",
    "    \"\"\"genLS(word)  is generator for Lyndon-(Shirshov) words with a given grading\n",
    "       Words are generated with the same multiplicities of letters as the input word, using the algorithm of Cattell and Sawada.\n",
    "       \n",
    "       Note: Words are generated in reverse lexicographic order!\n",
    "       \n",
    "       Example: genLS(\"aaabbc\") will generate all LS words with 3x 'a', 2x 'b', and 1x 'c'\n",
    "        --> 'ababac', 'aacbab', 'aacabb', 'aabcab', 'aabbac', 'aabacb', 'aababc', 'aaacbb', 'aaabcb', 'aaabbc'\n",
    "    \"\"\"\n",
    "    if root:\n",
    "        N = len(word)\n",
    "        if N < 2:\n",
    "            yield word\n",
    "        \n",
    "        tmp    = sorted(list(set(word)))\n",
    "        count  = ValuedLList([word.count(letter) for letter in tmp])\n",
    "        word   = tmp              # later iterations need alphabet\n",
    "        K      = len(word)\n",
    "        LSWord = [K-1] * (N + 1)    # Cattell's algorithm uses 1-indexing... ugh\n",
    "        tmp    = [0] * (N + 1)\n",
    "        \n",
    "        LSWord[1] = 0             # Cattell's algorithm uses 1-indexing... ugh\n",
    "        count.decrement(0)\n",
    "        \n",
    "    if count.mult(-1) == N-t+1:\n",
    "        if count.mult(-1) == tmp[t-p] and N == p:\n",
    "            yield(''.join(word[num] for num in LSWord[1:]))\n",
    "        elif count.mult(-1) > tmp[t-p]:\n",
    "            yield(''.join(word[num] for num in LSWord[1:]))\n",
    "            \n",
    "    elif count.mult(0) != N-t+1:\n",
    "        j = count.head.index\n",
    "        ss = s\n",
    "        while j >= LSWord[t-p]:\n",
    "            tmp[s]    = t-s\n",
    "            LSWord[t] = j\n",
    "            \n",
    "            count.decrement(j)\n",
    "            \n",
    "            if j != K-1:\n",
    "                ss = t+1\n",
    "            if j == LSWord[t-p]:\n",
    "                yield from genLS(word,t+1,p,ss,N,K,False,LSWord,count,tmp)\n",
    "            else:\n",
    "                yield from genLS(word,t+1,t,ss,N,K,False,LSWord,count,tmp)\n",
    "                \n",
    "            count.increment(j)\n",
    "            \n",
    "            j = count.nextval(j)\n",
    "            \n",
    "        LSWord[t] = K-1\n",
    "\n",
    "\n",
    "\n",
    "#######################################################\n",
    "#######################################################\n",
    "#  Lyndon words are minimal in their cyclic ordering class\n",
    "#   usually we use lexicographic ordering\n",
    "#   alternately we could use deg-lex ordering\n",
    "###########################################################\n",
    "def genDL():\n",
    "    passs\n",
    "\n",
    "#   JavaScript code:   (TODO: clean and convert this to Python!)\n",
    "#//////////////////////////////////////////////////////////////////////////////// \n",
    "#// toDLWord\n",
    "#//   converts LS word to DL word \n",
    "#//\n",
    "#function toDLWord( word ) {\n",
    "#\treturn toDL( word.split(''), word.charAt(0) );\n",
    "#}\n",
    "#function toDL( word, wordMin ) {\n",
    "#\tif (word.length <=1 )\n",
    "#\t\t\treturn word[0];\n",
    "#\n",
    "#\tvar i, j;\n",
    "#\tvar newWord = [];\n",
    "#\tvar newMin = \"999999999999999999\";\n",
    "#\n",
    "#\tfor (i=0; (i < word.length) && (word[i] != wordMin); i++) ;\n",
    "#\n",
    "#\tj = i;\n",
    "#\n",
    "#\twhile (i < word.length+j)  {\n",
    "#\n",
    "#\t\tvar subWord = word[i];\n",
    "#\n",
    "#\t\tfor (i++ ; (i < word.length) && (word[i] == wordMin); i++)  {\n",
    "#\t\t\tsubWord = subWord+word[i];\n",
    "#\t\t}\n",
    "#\t\t\n",
    "#\t\tif (i != word.length)\n",
    "#\t\t\tsubWord = subWord+word[i];\n",
    "#\t\telse \n",
    "#\t\t\ti--;\n",
    "#\n",
    "#\t\tfor (i++ ; (i < word.length + j) && (word[i] != wordMin); i++)\n",
    "#\t\t\tsubWord = subWord+word[(i % word.length)];\n",
    "#\n",
    "#\t\tnewWord.push( subWord );\n",
    "#\t\tif (parseInt(subWord.replace(/\\D/g,'')) < parseInt(newMin.replace(/\\D/g,''))) \n",
    "#\t\t\tnewMin = subWord;\n",
    "#\t}\n",
    "#\n",
    "#\treturn toDL( newWord, newMin );\n",
    "#}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Test the code!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['aaaabbbd', 'aaaabbdb', 'aaaabdbb', 'aaaadbbb', 'aaababbd', 'aaababdb', 'aaabadbb', 'aaabbabd', 'aaabbadb', 'aaabbbad', 'aaabbdab', 'aaabdabb', 'aaabdbab', 'aaadabbb', 'aaadbabb', 'aaadbbab', 'aabaabbd', 'aabaabdb', 'aabaadbb', 'aabababd', 'aababadb', 'aababbad', 'aababdab', 'aabadabb', 'aabadbab', 'aabbaabd', 'aabbaadb', 'aabbabad', 'aabbadab', 'aabbbaad', 'aabdabab', 'aadababb', 'aadabbab', 'aadbabab', 'abababad']\n",
      "Time:  0.0017171100043924525\n",
      "['abababad', 'aadbabab', 'aadabbab', 'aadababb', 'aabdabab', 'aabbbaad', 'aabbadab', 'aabbabad', 'aabbaadb', 'aabbaabd', 'aabadbab', 'aabadabb', 'aababdab', 'aababbad', 'aababadb', 'aabababd', 'aabaadbb', 'aabaabdb', 'aabaabbd', 'aaadbbab', 'aaadbabb', 'aaadabbb', 'aaabdbab', 'aaabdabb', 'aaabbdab', 'aaabbbad', 'aaabbadb', 'aaabbabd', 'aaabadbb', 'aaababdb', 'aaababbd', 'aaaadbbb', 'aaaabdbb', 'aaaabbdb', 'aaaabbbd']\n",
      "Time:  0.0005582200028584339\n"
     ]
    }
   ],
   "source": [
    "#################################################\n",
    "#     TESTING BLOCK!!!!                         #\n",
    "#################################################\n",
    "\n",
    "import timeit\n",
    "\n",
    "\n",
    "start = timeit.default_timer()\n",
    "print(list(genLS_old(\"aaaabbbd\")))\n",
    "stop = timeit.default_timer()\n",
    "\n",
    "print('Time: ', stop - start)  \n",
    "\n",
    "\n",
    "start = timeit.default_timer()\n",
    "print(list(genLS(\"aaaabbbd\")))\n",
    "stop = timeit.default_timer()\n",
    "\n",
    "print('Time: ', stop - start)  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Making Lie bases from LS words!\n",
    "\n",
    "Once  you have a list of LS words basically any reasonable method you come up with for systematically creating (nonzero) brackets will yield a Lie basis.  There is a long and honorable tradition in algebra of coming up with new Lie bases.  There are lots of different ones.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "#######################################################################\n",
    "# Code below makes Lie bases from LS words using different rules      #\n",
    "#                                                                     #\n",
    "# Most of this code is directly translated from my old Javascript     # \n",
    "#  code from 2015 without any optimazation or cleaning....            #\n",
    "#    (see pairing.html)                                               \n",
    "#######################################################################\n",
    "\n",
    "from coLie import *\n",
    "\n",
    "############################################################\n",
    "# This makes the classical bracketing on an LS word - recursively defined as\n",
    "#    B(w) = [ B(a) , B(b) ]  where w = ab and b is a maximal LS subword\n",
    "#\n",
    "# There are two standard approaches to making this bracketing --\n",
    "#   Inside->out (inductive): finding the inner-most bracket first  \n",
    "#                                (look for \"right-most inversion\")\n",
    "#   Outside->in (recursive): finding outer-most bracket first\n",
    "#                                (look for largest Lyndon suffix)\n",
    "#\n",
    "#  ... the code below is outside-in... this looks unnecessarily complex??? oh well.\n",
    "###########################################################\n",
    "def bracketStd(word):\n",
    "    \"\"\"Convert Lyndon word to standard Lie bracketing\"\"\"\n",
    "    if len(word) == 1:\n",
    "        return LieTree(word)\n",
    "    \n",
    "    end = len(word)-1\n",
    "    newprefix , myprefix = 1 , 0     # number of times initial letter is repeated\n",
    "    split = end\n",
    "    \n",
    "    repeat = True\n",
    "    \n",
    "    for j in range(end-1, 0, -1):\n",
    "        if repeat:                     # if current word is repeating suffix\n",
    "            if word[j] == word[end]:   # if repeat continues\n",
    "                end -= 1               #   move repeat pointer \n",
    "            else:\n",
    "                repeat = False         # no longer repeating suffix\n",
    "                end = len(word) - 1    #   reset repeat pointer\n",
    "                \n",
    "        if word[j] < word[split]:       # found new low -- better suffix start!\n",
    "            newprefix , myprefix = 1 , 1\n",
    "            split = j\n",
    "            repeat = True               # start checking for repeats again\n",
    "            \n",
    "        elif word[j] > word[split]:     # not a possible Lyndon suffix start!\n",
    "            myprefix = 0                # reset repeats to 0\n",
    "            \n",
    "        else:                        # possible cutpoint! (word[j] == word[split])\n",
    "            myprefix += 1            #  count # repeating letters at cutpoint\n",
    "                \n",
    "            if not repeat:\n",
    "                if myprefix == newprefix: # compare new cutpoint to old cutpoint\n",
    "                    i = 1\n",
    "                    while split+i < len(word) and word[j+i] == word[split+i]:\n",
    "                        i += 1\n",
    "                    if split+i < len(word) and word[j+i] < word[split+i]:\n",
    "                        split  = j\n",
    "                        repeat = True\n",
    "                elif myprefix > newprefix: # found longer prefix -- new cutpoint\n",
    "                    newprefix = myprefix\n",
    "                    split = j\n",
    "                    repeat = True                             \n",
    "                \n",
    "    \n",
    "    bracket = LieTree()\n",
    "    bracket.bracket = [ bracketStd(word[:split]) , bracketStd(word[split:]) ]\n",
    "    \n",
    "    return bracket  \n",
    "\n",
    "\n",
    "\n",
    "#########################################################\n",
    "# see also algorithm by Sawada and Ruskey (2002) .. generating words and brackets at same time\n",
    "#  https://webhome.cs.uvic.ca/~ruskey/Publications/LieBasis/LieBasis.pdf\n",
    "#          Journal of Algorithms 46 (2003) 21-26\n",
    "#\n",
    "# algorithm is implemented in C at http://combos.org/necklace\n",
    "##########################################################\n",
    "\n",
    "\n",
    "\n",
    "###########################################################\n",
    "# code below is translated from my javascript code\n",
    "#\n",
    "# Note: this is a basis by [WaSh15] and pairs diagonally with the star basis for symbols!!!\n",
    "# \n",
    "# TODO: modify this so that it will also left-greedy bracket non-Lyndon words!\n",
    "###########################################################\n",
    "def bracketLeft(word):\n",
    "    \"\"\"Convert Lyndon word to left-greedy bracketing\"\"\"\n",
    "    if len(word) <= 1:\n",
    "        return LieTree(word)\n",
    "    \n",
    "    i , j = 0 , 1\n",
    "\n",
    "# Idea:  look for repeated subword in topmost partition  ww..wx\n",
    "#  by moving two pointers across the word and looking for repetitions\n",
    "\n",
    "# current code requires word to be LS. more general version?\n",
    "#\n",
    "#    while j < len(word)-1 and word[i] <= word[j]: # 2nd condition only needed for deg-lex words?\n",
    "    while j < len(word)-1:                         # 2nd condition never fails for LS words.\n",
    "        if word[i] == word[j]:\n",
    "            i += 1\n",
    "        else:\n",
    "#            if word[i] > word[j]:    # test necessity of 2nd condition\n",
    "#                print(\"oops\") \n",
    "            i = 0\n",
    "        j += 1\n",
    "    \n",
    "    bracket = LieTree()\n",
    "    bracket.bracket = [ bracketLeft(word[:j-i]) , bracketLeft(word[j-i:]) ]\n",
    "    \n",
    "    return bracket\n",
    "\n",
    "\n",
    "\n",
    "###########################################################\n",
    "# code below is translated from my old javascript code\n",
    "#\n",
    "# I'm pretty sure this is a basis, but I don't remember if I/anyone ever proved it....\n",
    "#\n",
    "# TODO: verify whether this will right-greedy bracket non-Lyndon words!\n",
    "###########################################################\n",
    "def bracketRight(word):\n",
    "    \"\"\"Convert Lyndon word to right-greedy bracketing\"\"\"\n",
    "    return bracketRG(list(word))\n",
    "\n",
    "def bracketRG(word):\n",
    "    if len(word) == 1:\n",
    "        return word[0] if isinstance(word[0],LieTree) else LieTree(word[0])\n",
    "\n",
    "    newWord = []\n",
    "    \n",
    "    i = 1\n",
    "    while i < len(word):\n",
    "        subbracket = bracketRG([word[i-1]])\n",
    "        \n",
    "        while i < len(word) and str(word[i]) != str(word[0]):\n",
    "            tmpbracket = LieTree()\n",
    "            tmpbracket.bracket = [ bracketRG([subbracket]) , bracketRG([word[i]]) ]\n",
    "            subbracket = tmpbracket\n",
    "            i += 1\n",
    "        \n",
    "        newWord.append(subbracket)\n",
    "        i += 1\n",
    "        \n",
    "    return bracketRG(newWord)\n",
    "\n",
    "\n",
    "\n",
    "###########################################################        \n",
    "# \"Configuration basis\"  This is a basis by:\n",
    "#   B. Walter.  The configuration basis of a Lie algebra and its dual\n",
    "#      https://arxiv.org/abs/1010.4765\n",
    "#\n",
    "# this is a direct translation of my javascript code to python\n",
    "###########################################################\n",
    "def bracketCfg(word):\n",
    "    \"\"\"Convert Lyndon word to Configuration bracketing\"\"\"\n",
    "    return LieTree(bracketConfig(list(word)))\n",
    "\n",
    "\n",
    "def bracketConfig(word):\n",
    "    if len(word) == 1:\n",
    "        return word[0]\n",
    "    \n",
    "    newWord = []\n",
    "    \n",
    "    start , i = 0 , 1 \n",
    "    \n",
    "    while i < len(word):\n",
    "        bracket = ['[', word[start] ]\n",
    "        \n",
    "        while word[i] == word[0]:\n",
    "            bracket.extend([ ',[' , word[i] ])\n",
    "            i += 1\n",
    "        bracket.extend([\",\" , word[i]])\n",
    "        bracket.extend([\"]\"] * (i-start))\n",
    "                \n",
    "        i += 1\n",
    "        while i < len(word) and word[i] != word[0]:\n",
    "            bracket.insert(0, '[')\n",
    "            bracket.extend([',' , word[i] , ']'])\n",
    "            i += 1\n",
    "            \n",
    "        newWord.append(''.join(bracket))\n",
    "                \n",
    "        start = i\n",
    "        i += 1\n",
    "        \n",
    "    return bracketConfig(newWord)\n",
    "    \n",
    "\n",
    "\n",
    "###########################################################\n",
    "# \"right normed\" basis of Chibrikov:\n",
    "#   https://core.ac.uk/download/pdf/82357333.pdf\n",
    "#\n",
    "# this is a direct translation of my javascript code to python\n",
    "###########################################################\n",
    "def bracketChib(word):\n",
    "    \"\"\"Convert Lyndon word to Chibrikov's bracketing\"\"\"\n",
    "    return LieTree(bracketChibrikov(list(word)))\n",
    "\n",
    "def bracketChibrikov(word):\n",
    "    if len(word) == 1:\n",
    "        return word[0]\n",
    "    \n",
    "    newWord = []\n",
    "    \n",
    "    end , i = len(word)-1 , len(word)-2     \n",
    "\n",
    "    while i>=0:\n",
    "        bracket = [word[end], ']']\n",
    "        \n",
    "        while word[i] != word[0]:\n",
    "            bracket.insert(0,']')\n",
    "            bracket.insert(0,word[i])\n",
    "            i -= 1\n",
    "\n",
    "        bracket.insert(0,word[i])\n",
    "        \n",
    "        while end > i:\n",
    "            bracket.insert(0,'[')\n",
    "            end -= 1\n",
    "        \n",
    "        i -= 1\n",
    "        while i >= 0 and word[i] == word[0]:\n",
    "            bracket.insert(0,word[i])\n",
    "            bracket.insert(0,'[')\n",
    "            bracket.append(']')\n",
    "            i -= 1\n",
    "            \n",
    "        newWord.insert(0,''.join(bracket))\n",
    "        \n",
    "        end = i\n",
    "        i -= 1\n",
    "        \n",
    "    return bracketChibrikov(newWord)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Test the code!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Standard:\n",
      "abababb -> [[a,b],[[a,b],[[a,b],b]]]\n",
      "aabbbab -> [[a,[[[a,b],b],b]],[a,b]]\n",
      "aabbabb -> [[a,[[a,b],b]],[[a,b],b]]\n",
      "aababbb -> [a,[[a,b],[[[a,b],b],b]]]\n",
      "aaabbbb -> [a,[a,[[[[a,b],b],b],b]]]\n",
      "[1, 3, -2, 3, 0]\n",
      "[0, 1, -2, 2, -4]\n",
      "[0, 0, 1, -3, 6]\n",
      "[0, 0, 0, 1, -4]\n",
      "[0, 0, 0, 0, 1]\n",
      "\n",
      " Left-Greedy:\n",
      "abababb -> [[a,b],[[a,b],[[a,b],b]]]\n",
      "aabbbab -> [[[[a,[a,b]],b],b],[a,b]]\n",
      "aabbabb -> [[[[a,[a,b]],b],[a,b]],b]\n",
      "aababbb -> [[[[a,[a,b]],[a,b]],b],b]\n",
      "aaabbbb -> [[[[a,[a,[a,b]]],b],b],b]\n",
      "[1, 2, 0, 4, 0]\n",
      "[0, 1, -1, 0, 0]\n",
      "[0, 0, 1, -1, 0]\n",
      "[0, 0, 0, 1, -3]\n",
      "[0, 0, 0, 0, 1]\n",
      "\n",
      " Right-Greedy:\n",
      "abababb -> [[a,b],[[a,b],[[a,b],b]]]\n",
      "aabbbab -> [[a,[[[a,b],b],b]],[a,b]]\n",
      "aabbabb -> [[a,[[a,b],b]],[[a,b],b]]\n",
      "aababbb -> [[a,[a,b]],[[[a,b],b],b]]\n",
      "aaabbbb -> [a,[a,[[[[a,b],b],b],b]]]\n",
      "[1, 3, -2, 6, 0]\n",
      "[0, 1, -2, 3, -4]\n",
      "[0, 0, 1, -3, 6]\n",
      "[0, 0, 0, 1, -4]\n",
      "[0, 0, 0, 0, 1]\n",
      "\n",
      " Configuration\n",
      "abababb -> [[a,b],[[a,b],[[a,b],b]]]\n",
      "aabbbab -> [[[[a,[a,b]],b],b],[a,b]]\n",
      "aabbabb -> [[[a,[a,b]],b],[[a,b],b]]\n",
      "aababbb -> [[a,[a,b]],[[[a,b],b],b]]\n",
      "aaabbbb -> [[[[a,[a,[a,b]]],b],b],b]\n",
      "[1, 2, -2, 6, 0]\n",
      "[0, 1, -2, 3, 0]\n",
      "[0, 0, 1, -3, 0]\n",
      "[0, 0, 0, 1, -3]\n",
      "[0, 0, 0, 0, 1]\n",
      "\n",
      "  Chibrikov\n",
      "abababb -> [[a,b],[[a,b],[[a,b],b]]]\n",
      "aabbbab -> [[a,[[[a,b],b],b]],[a,b]]\n",
      "aabbabb -> [[a,[[a,b],b]],[[a,b],b]]\n",
      "aababbb -> [[a,[a,b]],[[[a,b],b],b]]\n",
      "aaabbbb -> [a,[a,[[[[a,b],b],b],b]]]\n",
      "[1, 3, -2, 6, 0]\n",
      "[0, 1, -2, 3, -4]\n",
      "[0, 0, 1, -3, 6]\n",
      "[0, 0, 0, 1, -4]\n",
      "[0, 0, 0, 0, 1]\n"
     ]
    }
   ],
   "source": [
    "#################################################\n",
    "#     TESTING BLOCK!!!!                         #\n",
    "#################################################\n",
    "\n",
    "from coLie import *\n",
    "\n",
    "print(\" Standard:\")\n",
    "\n",
    "for word in genLS(\"abababb\"):   # check bracket creation\n",
    "    print(f'{word} -> {bracketStd(word)}')\n",
    "for eil in genLS(\"abababb\"):    # verify pairing matrix (invertible = basis)\n",
    "    print([EilWord(eil) * bracketStd(lie) for lie in genLS(\"abababb\")])\n",
    "    \n",
    "print(\"\\n Left-Greedy:\")\n",
    "\n",
    "for word in genLS(\"abababb\"):   # check bracket creation\n",
    "    print(f'{word} -> {bracketLeft(word)}')\n",
    "for eil in genLS(\"abababb\"):    # verify pairing matrix (invertible = basis)\n",
    "    print([EilWord(eil) * bracketLeft(lie) for lie in genLS(\"abababb\")])   \n",
    "    \n",
    "print(\"\\n Right-Greedy:\")\n",
    "\n",
    "for word in genLS(\"abababb\"):   # check bracket creation\n",
    "    print(f'{word} -> {bracketRight(word)}')\n",
    "for eil in genLS(\"abababb\"):    # verify pairing matrix (invertible = basis)\n",
    "    print([EilWord(eil) * bracketRight(lie) for lie in genLS(\"abababb\")])\n",
    "\n",
    "print(\"\\n Configuration\")\n",
    "\n",
    "for word in genLS(\"abababb\"):   # check bracket creation\n",
    "    print(f'{word} -> {bracketCfg(word)}')\n",
    "for eil in genLS(\"abababb\"):    # verify pairing matrix (invertible = basis)\n",
    "    print([EilWord(eil) * bracketCfg(lie) for lie in genLS(\"abababb\")])\n",
    "\n",
    "print(\"\\n  Chibrikov\")\n",
    "\n",
    "for word in genLS(\"abababb\"):   # check bracket creation\n",
    "    print(f'{word} -> {bracketChib(word)}')\n",
    "for eil in genLS(\"abababb\"):\n",
    "    print([EilWord(eil) * bracketChib(lie) for lie in genLS(\"abababb\")])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Note that the pairing matrices above are all upper triangular.  This is a general fact, and is the essential ingredient in the proof that they are bases (though the original authors didn't use this language)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Symbol Bases\n",
    "\n",
    "The LS and deg-lex LS words are bases for Eil words.\n",
    "\n",
    "Alternatively we can use the \"Star Symbol\" basis for Eil symbols!\n",
    "\n",
    "The star symbol basis is connected to the left-greedy recursive partitioning of a word (and the left-greedy Lie bracketing above).\n",
    "* An **$a$-simple** word is $a^nx$ where $x\\neq a$\n",
    "* An **$a$-simple partition** of a word is $w=\\alpha_1\\alpha_2\\cdots\\alpha_n$ where each $\\alpha_i$ is an $a$-simple word.  Note that LS words have unique $a$-simple partitions.\n",
    "* Viewing $a$-simple words as a new alphabet we can repeat (if you order lexicographically then $a$-simple partitions are themselves LS words in the alphabet of $a$-simple words.)\n",
    "\n",
    "* The left greedy bracketing is defined (recursively) by\n",
    "    - $[a^nx] = [a,\\,[a,\\,\\cdots[a,\\,x]\\;]]$\n",
    "    - $[\\alpha^n\\beta] = \\bigl[[\\alpha],\\,\\bigl[[\\alpha],\\,\\cdots\\bigl[[\\alpha],[\\beta]\\bigr]\\;\\bigr]\\bigr]$\n",
    "* The star symbol is defined (recursively) by\n",
    "    - $\\star a^nx = (a)(a)\\cdots(a)x$\n",
    "    - $\\star \\alpha^n \\beta = \\bigl(\\star \\alpha\\bigr)\\,\\bigl(\\star \\alpha\\bigr)\\cdots\\bigl(\\star\\alpha\\bigr)\\,\\star\\!\\beta$\n",
    "\n",
    "**Note:** We can make star symbols out of non-LS words as well!\n",
    "\n",
    "**Note:** Star symbols have the **very** special property that their cobrackets are also star symbols!  (Compare to LS words, whose cobrackets will usually not be LS!)\n",
    "\n",
    "\n",
    "### Other symbol bases???\n",
    "\n",
    "I don't know... I showed that the star symbols make a basis.  They should also be a \"dual monomial basis\" to left greedy brackets (we'll test this in the code below!).  I was satisfied enough with that, so I didn't search for any other bases....  I guess, the star symbols are so perfect that I didn't bother looking for others."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "from coLie import *\n",
    "\n",
    "###########################################################\n",
    "# code below is modification of bracketLeft() code\n",
    "#\n",
    "# Note: this is a basis by [WaSh15] and pairs nicely with the leftGreedy basis for Lie algebras\n",
    "###########################################################\n",
    "def symbolStar(word):\n",
    "    \"\"\"Convert Lyndon word into coLie star symbol\"\"\"\n",
    "    if len(word) <= 1:\n",
    "        return EilTree(word)\n",
    "    \n",
    "    i , j = 0 , 1\n",
    "    N = len(word)\n",
    "    \n",
    "    # look for repeated subword in topmost partition  ww..wx\n",
    "    #  by moving two pointers across the word and looking for repetitions\n",
    "    #\n",
    "    while j != N-1:    # current code requires word to be LS. more general version?\n",
    "        if word[i] == word[j]: \n",
    "            i += 1\n",
    "        else:\n",
    "            i = 0\n",
    "        j += 1\n",
    "    \n",
    "    k = j - i       # width of subword w in top partition ww..wx\n",
    "    \n",
    "    subsymbols = [symbolStar(word[:k])]  # this is subword w\n",
    "    \n",
    "    n = k         \n",
    "    while n < N-k:  # attach repetitions of subword (if any)\n",
    "        subsymbols[:0] = [subsymbols[0].copy()]\n",
    "        n += k\n",
    "    \n",
    "    symbol = symbolStar(word[n:]) # this is the suffix word x\n",
    "    symbol.extend(subsymbols)     # stick the w's onto the x\n",
    "    \n",
    "    return symbol\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Test the code!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(((a)b)(a)c)(((a)b)(a)c)((a)b)(a)d has weight 11\n",
      "((a)b)(a)c has weight 3\n",
      "((a)b)(a)c has weight 3\n",
      "(a)b has weight 1\n",
      "a has weight 0\n",
      "\n",
      "(((a)b)(a)c)(((a)b)(a)c)((a)b)(a)d has cobracket:\n",
      " ((a)b)(a)c x (((a)b)(a)c)((a)b)(a)d\n",
      " (a)b x ((a)c)(((a)b)(a)c)((a)b)(a)d\n",
      " a x ((b)(a)c)(((a)b)(a)c)((a)b)(a)d\n",
      " a x (((a)b)c)(((a)b)(a)c)((a)b)(a)d\n",
      " ((a)b)(a)c x (((a)b)(a)c)((a)b)(a)d\n",
      " (a)b x (((a)b)(a)c)((a)c)((a)b)(a)d\n",
      " a x (((a)b)(a)c)((b)(a)c)((a)b)(a)d\n",
      " a x (((a)b)(a)c)(((a)b)c)((a)b)(a)d\n",
      " (a)b x (((a)b)(a)c)(((a)b)(a)c)(a)d\n",
      " a x (((a)b)(a)c)(((a)b)(a)c)(b)(a)d\n",
      " a x (((a)b)(a)c)(((a)b)(a)c)((a)b)d\n",
      "\n",
      "(a)(a)(a)(a)b\n",
      "[a,[a,[a,[a,b]]]]\n",
      " pair to 24\n",
      "\n",
      "((a)b)((a)b)((a)b)b\n",
      "[[a,b],[[a,b],[[a,b],b]]]\n",
      " pair to 6\n",
      "\n",
      "(((a)b)(a)c)(((a)b)(a)c)((a)b)(a)d\n",
      "[[[a,b],[a,c]],[[[a,b],[a,c]],[[a,b],[a,d]]]]\n",
      " pair to 2\n",
      "\n",
      "\n",
      "abababb -> ((a)b)((a)b)((a)b)b\n",
      "aabbbab -> ((((a)(a)b)b)b)(a)b\n",
      "aabbabb -> ((((a)(a)b)b)(a)b)b\n",
      "aababbb -> ((((a)(a)b)(a)b)b)b\n",
      "aaabbbb -> ((((a)(a)(a)b)b)b)b\n",
      "[6, 0, 0, 0, 0]\n",
      "[0, 2, 0, 0, 0]\n",
      "[0, 0, 2, 0, 0]\n",
      "[0, 0, 0, 2, 0]\n",
      "[0, 0, 0, 0, 6]\n"
     ]
    }
   ],
   "source": [
    "#################################################\n",
    "#     TESTING BLOCK!!!!                         #\n",
    "#################################################\n",
    "\n",
    "eil = symbolStar(\"abacabacabad\")\n",
    "\n",
    "print(f'{str(eil)} has weight {eil.weight}')\n",
    "\n",
    "for subsymbol in eil.subsymbols:\n",
    "    print(f'{ str(subsymbol)} has weight {subsymbol.weight}')\n",
    "    \n",
    "print(f'\\n{str(eil)} has cobracket:')\n",
    "for cobr in eil.cobracket():\n",
    "    print(f' {str(cobr[0])} x {str(cobr[1])}')\n",
    "\n",
    "print()\n",
    "\n",
    "print(symbolStar(\"aaaab\"))\n",
    "print(bracketLeft(\"aaaab\"))\n",
    "print(f' pair to {symbolStar(\"aaaab\") * bracketLeft(\"aaaab\")}\\n')\n",
    "\n",
    "print(symbolStar(\"abababb\"))\n",
    "print(bracketLeft(\"abababb\"))\n",
    "print(f' pair to {symbolStar(\"abababb\") * bracketLeft(\"abababb\")}\\n')\n",
    "\n",
    "print(symbolStar(\"abacabacabad\"))\n",
    "print(bracketLeft(\"abacabacabad\"))\n",
    "print(f' pair to {symbolStar(\"abacabacabad\") * bracketLeft(\"abacabacabad\")}\\n')\n",
    "  \n",
    "print()\n",
    "\n",
    "for word in genLS(\"abababb\"):\n",
    "    print(f'{word} -> {str(symbolStar(word))}')\n",
    "    \n",
    "for eil in genLS(\"abababb\"):\n",
    "    print([symbolStar(eil) * bracketLeft(lie) for lie in genLS(\"abababb\")])\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Note that the pairing matrix for star symbols and left greedy brackets is diagonal!  This means we can quickly write general brackets in terms of left greedy brackets by computing pairings with corresponding star symbols.  (For other Lie bases we would need to invert the upper-triangular pairing matrix.)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ababac', 'aacbab', 'aacabb', 'aabcab', 'aabbac', 'aabacb', 'aababc', 'aaacbb', 'aaabcb', 'aaabbc']\n"
     ]
    }
   ],
   "source": [
    "print([lie for lie in genLS(\"aaabbc\")])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "argv": [
    "/usr/bin/python3",
    "-m",
    "ipykernel",
    "--HistoryManager.enabled=False",
    "--matplotlib=inline",
    "-c",
    "%config InlineBackend.figure_formats = set(['retina'])\nimport matplotlib; matplotlib.rcParams['figure.figsize'] = (12, 7)",
    "-f",
    "{connection_file}"
   ],
   "display_name": "Python 3 (system-wide)",
   "env": {
   },
   "language": "python",
   "metadata": {
    "cocalc": {
     "description": "Python 3 programming language",
     "priority": 100,
     "url": "https://www.python.org/"
    }
   },
   "name": "python3",
   "resource_dir": "/ext/jupyter/kernels/python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
